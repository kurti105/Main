{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a68513-37e7-436b-bb77-2674dfa62c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.11/site-packages (2024.12.0)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /opt/conda/lib/python3.11/site-packages (from s3fs) (2.13.3)\n",
      "Requirement already satisfied: fsspec==2024.12.0.* in /opt/conda/lib/python3.11/site-packages (from s3fs) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from s3fs) (3.9.5)\n",
      "Requirement already satisfied: botocore<1.34.163,>=1.34.70 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.34.162)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.17.0)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /opt/conda/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (0.12.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.18.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.34.163,>=1.34.70->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.34.163,>=1.34.70->aiobotocore<3.0.0,>=2.5.4->s3fs) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.34.163,>=1.34.70->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.26.19)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (0.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.163,>=1.34.70->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d0c701-c633-4afd-bf55-cd15c4d208c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 04:11:01.288838: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries & modules\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from torch import nn\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba4aef59-f7c0-435f-b781-a2f14ef49225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::041434534908:role/service-role/AmazonSageMaker-ExecutionRole-20250111T113739'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb30e9aa-35b1-4186-bd7c-4e69735ce4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-create the model class - FT_DistilBERT() (FT stands for Fine-Tuned)\n",
    "class FT_DistilBERT(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.block_1 = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.layer_2 = nn.Linear(in_features=768,\n",
    "                                 out_features=768)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.classifier_layer = nn.Linear(in_features=768,\n",
    "                                          out_features=num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, mask_ids):\n",
    "        # 1. Send through the DistilBERT pre-trained model\n",
    "        output = self.block_1(input_ids = input_ids,\n",
    "                              attention_mask = mask_ids)\n",
    "        hidden_state = output[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        \n",
    "        # 2. Send through the linear layer - this serves to increase the representational capacity of our model\n",
    "        output = self.layer_2(pooler)\n",
    "        # 3. Send through a non-linear activation function\n",
    "        output = self.activation(output)\n",
    "        # 4. Apply dropout to fight over-fitting\n",
    "        output = self.dropout(output)\n",
    "        # 5. Get the classification prediction (in logits)\n",
    "        output = self.classifier_layer(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9b735c0-d469-408e-b92d-b55fb9358024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to initialize a new model from the FT_DistilBERT class, and load the fine-tuned weights into it - this is specific for Notebooks where we need to define this extra code to get data from S3\n",
    "import boto3\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import tempfile\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Load model from S3 or local path\"\"\"\n",
    "    # 1. Initialize a new model\n",
    "    model = FT_DistilBERT(num_classes=4)\n",
    "\n",
    "    # 2. Check if the path is an S3 path\n",
    "    if model_dir.startswith('s3://'):\n",
    "        # Parse S3 path\n",
    "        bucket_name = model_dir.split('/')[2]\n",
    "        key = '/'.join(model_dir.split('/')[3:] + ['pytorch_distilbert_model_news.bin'])\n",
    "        \n",
    "        # Create S3 client\n",
    "        s3_client = boto3.client('s3')\n",
    "        \n",
    "        # Create a temporary file to download the model\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "            try:\n",
    "                # Download the file from S3\n",
    "                s3_client.download_file(bucket_name, key, tmp_file.name)\n",
    "                # Load the model weights\n",
    "                model_state_dict = torch.load(tmp_file.name, map_location=torch.device('cpu'))\n",
    "            finally:\n",
    "                # Clean up the temporary file\n",
    "                os.unlink(tmp_file.name)\n",
    "    else:\n",
    "        # Load from local path\n",
    "        state_dict_location = os.path.join(model_dir, 'pytorch_distilbert_model_news.bin')\n",
    "        model_state_dict = torch.load(state_dict_location, map_location=torch.device('cpu'))\n",
    "\n",
    "    # 3. Apply the trained state_dict to our newly initialized model\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9d91d63-5fb6-4e83-9e29-2f5726c1b92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1388/415515317.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(tmp_file.name, map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "s3_path = 's3://tk5-huggingface-multiclass-textclassification-bucket/output/tk5-generated-output/huggingface-pytorch-training-2025-01-19-06-52-30-974/output'\n",
    "model = model_fn(s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87d82637-2944-41eb-a334-7a5c93818bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define a function to conduct inference\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "MAX_LEN = 512\n",
    "\n",
    "def prediction_fn(model, input_data):\n",
    "\n",
    "    # 0. Setting up some device-agnostic code\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    # 1. Tokenize the data\n",
    "    data = tokenizer.encode_plus(text=input_data, \n",
    "                                 add_special_tokens=True, \n",
    "                                 max_length=MAX_LEN, \n",
    "                                 padding=\"max_length\", \n",
    "                                 truncation=True, \n",
    "                                 return_attention_mask=True)\n",
    "\n",
    "    input_ids = torch.tensor(data['input_ids']).to(device)\n",
    "    attention_mask = torch.tensor(data['attention_mask']).to(device)\n",
    "\n",
    "    # 2. Run the model with the data\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        probabilities = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "        class_names = ['BUSINESS', 'ENTERTAINMENT', 'HEALTH', 'SCIENCE'] # checked the correct order in 3.Script.ipynb\n",
    "        pred_class = probabilities.argmax(axis=1)[0].item()\n",
    "        pred_label = class_names[pred_class]\n",
    "\n",
    "        probabilities_dict = {class_names[i]: float(probabilities[0, i]) for i in range(len(class_names))}\n",
    "\n",
    "    return {'predicted_label': pred_label}, probabilities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d40b642b-187b-4c54-8ba5-8dbb0ed08ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Time travel is achievable - says top scientist from NASA'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input = {'inputs': 'Time travel is achievable - says top scientist from NASA'}\n",
    "sample_input['inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74968781-dd5b-4116-b56c-778994a2709e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'predicted_label': 'SCIENCE'},\n",
       " {'BUSINESS': 0.0012946061324328184,\n",
       "  'ENTERTAINMENT': 0.0004263822047505528,\n",
       "  'HEALTH': 0.000539263419341296,\n",
       "  'SCIENCE': 0.9977397918701172})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_fn(model=model, input_data=sample_input['inputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0210b70-e1aa-4b4f-ad5c-5a6874db3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tokenizer = tokenizer.encode_plus(sample_input['inputs'], \n",
    "                      add_special_tokens=True, \n",
    "                      max_length=MAX_LEN, \n",
    "                      padding=\"max_length\", \n",
    "                      truncation=True, \n",
    "                      return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed4b60fa-fb95-4f2b-81aa-37f62a8461a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_ids = torch.tensor(sample_tokenizer['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74fcde05-b75c-45ab-81ee-40a28f20b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mask = torch.tensor(sample_tokenizer['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27a305a8-a004-442c-a1e2-cb9a42fc5fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4184, -2.5290, -2.2942,  5.2289]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_logits = model(sample_ids, sample_mask)\n",
    "sample_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "928dabe7-c078-4470-8315-05c53b564989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.2946e-03, 4.2638e-04, 5.3926e-04, 9.9774e-01]],\n",
       "        grad_fn=<SoftmaxBackward0>),\n",
       " tensor(1., grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_probs = torch.softmax(sample_logits, dim=1)\n",
    "sample_probs, sample_probs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5395f3d9-3741-4675-97d1-8759fab97408",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['BUSINESS', 'ENTERTAINMENT', 'HEALTH', 'SCIENCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5fb4759-d719-49f1-80fd-ceeea9afdfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3]), 'SCIENCE')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_class = torch.argmax(sample_probs, dim=1)\n",
    "sample_class, class_names[sample_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc237898-8ac3-41ad-90f3-53618e2e7e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prob_dict = {class_names[i]: sample_probs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f1a19e2-1688-40e3-a977-811014a65de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0013, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_probs[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb859a5a-4729-49ca-afd2-58a594f57cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b91960e1-eba7-4d31-ac5b-a2aa9914b1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2051,  3604,  2003,  9353,  4048, 13331,  3468,  1011,  2758,\n",
       "          2327,  7155,  2013,  9274,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(sample_input['inputs'], return_tensors='pt', max_length=512, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ae471-3ec6-4369-adfd-054500a3280e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
